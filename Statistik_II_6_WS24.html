<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Einheit 6</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof.¬†Dr.¬†Stephan Goerigk" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/hygge.css" rel="stylesheet" />
    <link href="libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view/tile-view.js"></script>
    <script src="libs/fabric/fabric.min.js"></script>
    <link href="libs/xaringanExtra-scribble/scribble.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-scribble/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#EE0071"],"pen_size":4,"eraser_size":40,"palette":[]}) })</script>
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




name: Title slide
class: middle, left
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
# Statistik II
***
### Einheit 6: Multiple Regression
##### 27.11.2024 | Prof. Dr. Stephan Goerigk

---
class: top, left
### Multiple Regression

.pull-left[

#### Vorbemerkungen

* multiple Regression: das Regressionsmodell enth√§lt mehr als eine UV (Pr√§diktor)

* Ziel: Durch Hinzunahme weiterer Pr√§diktoren Vorhersagen bezogen auf die AV zu verbessern

**Abgrenzung zur mehrfaktoriellen ANOVA:**

* Bei der ANOVA sind UVs immer kategorial (Mittelwertesvergleiche zw. Gruppen/Kategorien)

* Im Regressionsmodell k√∂nnen kategoriale und stetige UVs verwendet und auch kombiniert werden

]

.pull-right[
.center[
&lt;img src="bilder/einvsmehrfaktoriell.png" width="520px" /&gt;
]
]

---
class: top, left
### Multiple Regression

.pull-left[

#### Weitere relevante Fragen

* Wie viel % der Gesamtvarianz der AV k√∂nnen die Pr√§diktoren **gemeinsam** erkl√§ren?

* Welcher Pr√§diktor hat den **gr√∂√üten** Vorhersagebeitrag?

* **Ver√§ndert** sich die St√§rke, Richtung (und Interpretation) des Effekts eines Pr√§diktors, wenn weitere Pr√§diktoren ber√ºcksichtigt werden? (z.B. √úberdeckungseffekte)
]

.pull-right[
.center[
&lt;img src="bilder/einvsmehrfaktoriell.png" width="520px" /&gt;
]
]

---
class: top, left
### Multiple Regression

#### Szenario in der Vorlesung

Wir beschr√§nken uns heute zun√§chst auf die einfachste Form der multiplen Regression: 

* Die Beschreibung des AV-Werts `\(Y_i\)` durch 2 stetige Pr√§diktoren und die Fehlervariable. 

* Hat man den Fall mit zwei Pr√§diktoren verstanden, ist die Generalisierung auf weitere Pr√§diktoren einfach.

Dies l√§sst sich durch die folgende **Erweiterung der Regressionsgleichung** darstellen:

`$$Y_i=a + \beta_1 \cdot X_{i1} + \beta_2 \cdot X_{i2} + \epsilon_i$$`

wobei: 

`$$\epsilon_i ~ N(0,\sigma^2)$$`

(Fehler normalverteilt mit Erwartungswert 0)

---
class: top, left
### Multiple Regression

#### Elemente der multiplen Regressionsgleichung

`$$Y_i=a + \beta_1 \cdot X_{i1} + \beta_2 \cdot X_{i2} + \epsilon_i$$`

* `\(X_1\)` und `\(X_2\)` sind Zufallsvariablen. Ihre Realisationen sind jeweils die Werte der zuf√§llig gezogenen Person `\(i\)` bez√ºglich der `\(UV_1\)` und der `\(UV_2\)`

* `\(a, \beta_1, \beta_2\)` und `\(\sigma^2\)` sind die zu sch√§tzenden Modellparameter

  * `\(a\)` = Y-Achsenabschnitt

  * `\(\beta_1\)` = Steigungsparameter der `\(UV_1\)`

  * `\(\beta_2\)` = Steigungsparameter der `\(UV_2\)`

  * `\(\sigma^2\)` = Varianz des Fehlerterms (f√ºr Hypothesen meist inhaltlich nicht relevant)

---
class: top, left
### Multiple Regression

#### Graphische Darstellung

.pull-left[
![](Statistik_II_6_WS24_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;
]

.pull-right[

* Einfache lineare Regression: 2-dimensionales Koordinatensystem mit X-Achse und Y-Achse

* Mutiple Regression (2 UVs): 3-dimensionales Koordinatensystem mit X-Achse, Y-Achse und Z-Achse

`\(\rightarrow\)` Es wird ein 3D-Streudiagramm dargestellt

  * Punkt = Beobachtungswert einer Person 
  
  * Kombination aus `\(AV\)` (Y-Achse), `\(UV_1\)` (X-Achse) und `\(UV_2\)` (Z-Achse) Wert
]

---
class: top, left
### Multiple Regression

#### Graphische Darstellung 

.pull-left[
![](Statistik_II_6_WS24_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;
]

.pull-right[

* Einfache lineare Regression: Modellfunktion dargestellt durch Regressionsgerade

  * Gerade definiert durch 1 Y-Achsenabschnitt + 1 Steigungsparameter

* Mutiple Regression (2 UVs): Modellfunktion dargestellt durch Regressionsebene

  * Ebene definiert durch 1 Y-Achsenabschnitt + 2 Steigungsparameter

* Auf der Ebene liegen alle durch das Modell erwarteten Werte
]

---
class: top, left
### Multiple Regression

#### Graphische Darstellung 

`$$Y_i=a + \beta_1 \cdot X_{i1} + \beta_2 \cdot X_{i2} + \epsilon_i$$`

.pull-left[
.center[
&lt;img src="bilder/plane.png" width="500px" /&gt;
]
]

.pull-right[
&lt;small&gt;

* `\(a\)` gibt den Y-Achsenabschnitt an

  * `\(a\)` ist der Wert der AV, wenn `\(UV_1\)` und `\(UV_2\)` gleich 0 sind
  
  * `\(a=a + \beta_1 \cdot 0 + \beta_2 \cdot 0\)`
  
  * Ob `\(a\)` sinnvoll interpretiert werden kann, h√§ngt davon ab, ob `\(UV_1=0\)` und `\(UV_2=0\)` inhaltlich sinnvolle Werte darstellen

* `\(\beta_1\)` gibt an, wie stark die Regressionsebene auf der `\(xy\)`-Gerade steigt bzw. f√§llt, wenn `\(UV_1\)` um 1 Einheit zunimmt.

* `\(\beta_2\)` gibt an, wie stark die Regressionsebene auf der `\(zy\)`-Gerade steigt bzw. f√§llt, wenn `\(UV_2\)` um 1 Einheit zunimmt.

&lt;/small&gt;
]

---
class: top, left
### Multiple Regression

#### Parametersch√§tzung


.pull-left[
![](Statistik_II_6_WS24_files/figure-html/unnamed-chunk-6-1.png)&lt;!-- --&gt;
]

.pull-right[
* Die unbekannten Modellparameter `\(a, \beta_1\)` und `\(\beta_2\)` k√∂nnen mit der **Methode der kleinsten Quadrate** bestimmt werden (wie bei einfacher Regression)

* Die Ebene wird so definiert, dass die Residuen minimiert werden

* Die Formeln sind aufwendig, weswegen wir uns hier auf die Berechnung in R beschr√§nken
]


---
class: top, left
### Multiple Regression

#### Standardfehler der Modellparameter

* W√§hrend wir die Sch√§tzung der Modellparameter R √ºberlassen, schauen wir uns einmal die Berechnung der Standardfehler f√ºr `\(\beta_1\)` und `\(\beta_2\)` an.

* Diese brauchen wir, um Hypothesentests/Konfidenzintervalle f√ºr diese Parameter zu berechnen

`$$SE(B_1) = \sqrt{Var(B_1)} = \sqrt{\frac{1}{1-r^2_{x1x2}}\cdot\frac{\sigma^2}{\sum\limits _{i=1}^{n}(x_{i1}-\bar{x}_1)^2}}$$`
`$$SE(B_2) = \sqrt{Var(B_2)} = \sqrt{\frac{1}{1-r^2_{x1x2}}\cdot\frac{\sigma^2}{\sum\limits _{i=1}^{n}(x_{i2}-\bar{x}_2)^2}}$$`

* `\(r^2_{x1x2}\)` stellt die quadrierte Korrelation zwischen den beiden Pr√§diktoren dar

* `\(\sigma^2\)` wird durch die Stichprobenvarianz `\(s^2\)` gesch√§tzt.

---
class: top, left
### Multiple Regression

#### Konfidenzintervalle der Modellparameter

Die Konfidenzintervalle f√ºr `\(\beta_1\)` und `\(\beta_2\)` lassen sich wie folgt berechnen:

`$$\beta \pm t_{1-\frac{\alpha}{2} \cdot SE(B_j)}$$`

* Die Freiheitsgerade f√ºr den t-Wert errechnen sich als `\(df=n-3\)`

---
class: top, left
### Multiple Regression

.pull-left[
#### Beispiel: Risikofaktoren f√ºr Aggression bei Kindern

* Wissenschaftler:innen haben Daten erhoben `\((N=50)\)`, um Risikofaktoren f√ºr Aggression bei Kindern zu identifizieren.

* Folgende Variablen wurden gemessen

  * Aggression (AV, 1-100 Punkte)
  * TV (UV, in Stunden/Tag)
  * Emotionsregulation (UV, 1-100 Punkte)
  * Ausgrenzungserfahrung (UV, 1-100 Punkte)
  
* Die ersten 15 F√§lle sind in der Tabelle rechts dargestellt.
]


.pull-right[


&lt;table class=" lightable-classic" style='font-size: 16px; font-family: "Arial Narrow", "Source Sans Pro", sans-serif; width: auto !important; margin-left: auto; margin-right: auto;'&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; Aggression &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; TV &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Emotionsregulation &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Ausgrenzung &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 53 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 55 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 57 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 58 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 58 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 80 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 71 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 61 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 49 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 62 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 41 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 49 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 82 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 36 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 63 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 66 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 40 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 62 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 44 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 47 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 30 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 51 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 56 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 56 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 54 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 68 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 38 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 76 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 78 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 65 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 56 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 38 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 65 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 31 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 61 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 52 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 98 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 53 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 64 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 37 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]

---
class: top, left
### Multiple Regression

.pull-left[
#### Beispiel: Risikofaktoren f√ºr Aggression bei Kindern

* Um einen 1. Eindruck zu gewinnen, lohnt es sich, die Daten zu visualisieren

* Wir schauen uns daf√ºr die bivariaten Streudiagramme an:
]

.pull-right[

![](Statistik_II_6_WS24_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;
]

---
class: top, left
### Multiple Regression

#### Modellsch√§tzung in R

.pull-left[
.code60[

```r
model = lm(Aggression ~ TV + Emotionsregulation, data = df)
summary(model)
```

```
## 
## Call:
## lm(formula = Aggression ~ TV + Emotionsregulation, data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -18.4040  -6.2847   0.7681   7.6023  19.7061 
## 
## Coefficients:
##                    Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)        86.24294    6.70484  12.863 &lt; 0.0000000000000002 ***
## TV                  0.11254    0.68819   0.164                0.871    
## Emotionsregulation -0.52752    0.09961  -5.296           0.00000308 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 9.604 on 47 degrees of freedom
## Multiple R-squared:  0.3852,	Adjusted R-squared:  0.3591 
## F-statistic: 14.73 on 2 and 47 DF,  p-value: 0.00001083
```
]
]

.pull-right[
Die Sch√§tzwerte f√ºr `\(a, \beta_1\)` und `\(\beta_2\)` k√∂nnen in der Spalte `Estimate` abgelesen werden

**Interpretation:**

* Der durchschnittliche Aggressionswert eines Kindes, das 0h TV sieht und einen Emotionsregulationsscore von 0 hat ist `\(a=86.24\)`

* Mit jeder zus√§tzlichen Stunde TV nimmt der Aggressionswert um `\(\beta_1= 0.11\)` Punkte zu.

* Mit jedem zus√§tzlichen Punkt auf der Emotionsregulationsskale nimmt der Aggressionswert um `\(\beta_2= -0.53\)` Punkte ab.
]

---
class: top, left
### Multiple Regression

#### Sch√§tzung der unbekannten Fehlervarianz `\(\sigma^2\)`

Die Sch√§tzfunktion f√ºr die unbekannte Fehlervarianz l√§sst sich darstellen als

`$$\hat{\sigma}^2 = \frac{1}{n-3}\sum\limits _{i=1}^{n}(Y_i-(A + B_1 \cdot X_{i2}))^2$$`

* Nach Umstellen und ziehen der Wurzel erh√§lt man den Standardsch√§tzfehler (wie in der einfachen Regression):

`$$s=\sqrt{\frac{\sum\limits _{i=1}^{n}e^2_i}{n-3}}$$`

`\(\rightarrow\)` Dies entspricht der Wurzel aus der Summe der quadrierten Residuen geteilt durch `\(n-3\)`

---
class: top, left
### Multiple Regression

#### Sch√§tzung der unbekannten Fehlervarianz `\(\sigma^2\)`

.pull-left[
.code60[

```r
model = lm(Aggression ~ TV + Emotionsregulation, data = df)
summary(model)
```

```
## 
## Call:
## lm(formula = Aggression ~ TV + Emotionsregulation, data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -18.4040  -6.2847   0.7681   7.6023  19.7061 
## 
## Coefficients:
##                    Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)        86.24294    6.70484  12.863 &lt; 0.0000000000000002 ***
## TV                  0.11254    0.68819   0.164                0.871    
## Emotionsregulation -0.52752    0.09961  -5.296           0.00000308 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 9.604 on 47 degrees of freedom
## Multiple R-squared:  0.3852,	Adjusted R-squared:  0.3591 
## F-statistic: 14.73 on 2 and 47 DF,  p-value: 0.00001083
```
]
]
.pull-right[
Dieser Wert findet sich im unteren Bereich des R Outputs:

`$$s=\sqrt{\frac{\sum\limits _{i=1}^{n}e^2_i}{n-3}}=9.60$$`
]

---
class: top, left
### Multiple Regression

#### Aufstellen der Modellgleichung

.pull-left[
.code60[

```r
model = lm(Aggression ~ TV + Emotionsregulation, data = df)
summary(model)
```

```
## 
## Call:
## lm(formula = Aggression ~ TV + Emotionsregulation, data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -18.4040  -6.2847   0.7681   7.6023  19.7061 
## 
## Coefficients:
##                    Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)        86.24294    6.70484  12.863 &lt; 0.0000000000000002 ***
## TV                  0.11254    0.68819   0.164                0.871    
## Emotionsregulation -0.52752    0.09961  -5.296           0.00000308 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 9.604 on 47 degrees of freedom
## Multiple R-squared:  0.3852,	Adjusted R-squared:  0.3591 
## F-statistic: 14.73 on 2 and 47 DF,  p-value: 0.00001083
```
]
]

.pull-right[
Allgemeine Form:

`$$Y_i=a + \beta_1 \cdot X_{i1} + \beta_2 \cdot X_{i2} + \epsilon_i$$`
mit `\(\epsilon_i ~ N(0,\sigma^2)\)`

In unserem Fall ergibt sich die Modellgleichung:

`$$Y_i= 86.24 + 0.11 \cdot X_{i1} + -0.53 \cdot X_{i2} + \epsilon_i$$`
mit `\(\epsilon_i ~N(0,9.60^2)\)`

`\(\rightarrow\)` Damit lie√üe sich ein konkreter Wert `\(Y_i\)` der AV sch√§tzen.
]

---
class: top, left
### Multiple Regression

#### Hypothesentests

Je nach konkreter Fragestellung muss entschieden werden, welche Parameter gesch√§tzt werden sollen bzw. welche Hypothesen getestet werden sollen.

Wir besprechen (zun√§chst) zwei Arten von Hypothesentests f√ºr die multiple Regression:

1. Hypothesentests f√ºr einzelne Modellparameter (z.B. eine Steigung)

  * `\(H_0: \beta_j=0\)`
  * Geeignet f√ºr Zusammenhangshypothesen 
  * keine Steigung = kein Zusammenhang (UV kann AV nicht systematisch vorhersagen)

2. Omnibus Tests

  * basieren auf Vergleich der Varianzaufkl√§rung (wie ANOVA)
  * pr√ºfen Signifikanz des Gesamtmodells `\((H_0:\)` alle Steigungen sind `\(0)\)`
  * erlauben Vergleich von Teilmodellen (z.B. Modell mit weiterem Pr√§diktor vs. Modell ohne weiteren Pr√§diktor)

---
class: top, left
### Multiple Regression

#### Hypothesentests f√ºr einzelne Modellparameter

.pull-left[
.code60[

```r
model = lm(Aggression ~ TV + Emotionsregulation, data = df)
summary(model)
```

```
## 
## Call:
## lm(formula = Aggression ~ TV + Emotionsregulation, data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -18.4040  -6.2847   0.7681   7.6023  19.7061 
## 
## Coefficients:
##                    Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)        86.24294    6.70484  12.863 &lt; 0.0000000000000002 ***
## TV                  0.11254    0.68819   0.164                0.871    
## Emotionsregulation -0.52752    0.09961  -5.296           0.00000308 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 9.604 on 47 degrees of freedom
## Multiple R-squared:  0.3852,	Adjusted R-squared:  0.3591 
## F-statistic: 14.73 on 2 and 47 DF,  p-value: 0.00001083
```
]
]

.pull-right[
1. Hypothesentest Y-Achsenabschnitt:

  * `\(H_0: a=0\)`
  * `\(H_1: a\neq0\)`

2. Hypothesentest Steigung (TV):
  * `\(H_0: \beta_1=0\)`
  * `\(H_1: \beta_1\neq0\)`

3. Hypothesentest Steigung (Emotionsregulation):
  * `\(H_0: \beta_2=0\)`
  * `\(H_1: \beta_2\neq0\)`
]

**Unser Beispiel:** Es soll √ºberpr√ºft werden, ob TV-Sehen bzw. Emotionsregulation linear mit Aggression zusammenh√§ngt, wenn der jeweils andere Pr√§diktor konstant gehalten wird.

---
class: top, left
### Multiple Regression

#### Hypothesentests f√ºr einzelne Modellparameter

.pull-left[
.code60[

```r
model = lm(Aggression ~ TV + Emotionsregulation, data = df)
summary(model)
```

```
## 
## Call:
## lm(formula = Aggression ~ TV + Emotionsregulation, data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -18.4040  -6.2847   0.7681   7.6023  19.7061 
## 
## Coefficients:
##                    Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)        86.24294    6.70484  12.863 &lt; 0.0000000000000002 ***
## TV                  0.11254    0.68819   0.164                0.871    
## Emotionsregulation -0.52752    0.09961  -5.296           0.00000308 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 9.604 on 47 degrees of freedom
## Multiple R-squared:  0.3852,	Adjusted R-squared:  0.3591 
## F-statistic: 14.73 on 2 and 47 DF,  p-value: 0.00001083
```
]
]

.pull-right[
`\(t_a = \frac{a}{SE(a)} = \frac{86.24}{6.70}=12.86\)` 

`\(t_{\beta_1} = \frac{\beta_1}{SE(\beta_1)}= \frac{0.11}{0.69} = 0.16\)` 

`\(t_{\beta_2} = \frac{\beta_2}{SE(\beta_2)}= \frac{-0.53}{0.10} = -5.30\)` 

* Unter der Geltung der `\(H_0\)` folgen diese Teststatistiken jeweils einer t-Verteilung mit `\(df=n-3\)`

* Der kritische Bereich ist jeweils beidseitig.

* `\(p\)`-Werte `\(&lt;.05\)` zeigen signifikantes Ergebnis an (Koeffizient `\(\neq0\)`)
]

---
class: top, left
### Multiple Regression

#### Hypothesentests f√ºr einzelne Modellparameter - Konfidenzintervalle

.pull-left[
.code60[

```r
model = lm(Aggression ~ TV + Emotionsregulation, data = df)
summary(model)
```

```
## 
## Call:
## lm(formula = Aggression ~ TV + Emotionsregulation, data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -18.4040  -6.2847   0.7681   7.6023  19.7061 
## 
## Coefficients:
##                    Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)        86.24294    6.70484  12.863 &lt; 0.0000000000000002 ***
## TV                  0.11254    0.68819   0.164                0.871    
## Emotionsregulation -0.52752    0.09961  -5.296           0.00000308 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 9.604 on 47 degrees of freedom
## Multiple R-squared:  0.3852,	Adjusted R-squared:  0.3591 
## F-statistic: 14.73 on 2 and 47 DF,  p-value: 0.00001083
```
]
]

.pull-right[
.code60[

```r
confint(model)
```

```
##                         2.5 %     97.5 %
## (Intercept)        72.7545432 99.7313311
## TV                 -1.2719190  1.4970047
## Emotionsregulation -0.7279233 -0.3271248
```
]

* KI zeigt Bereich an, in welchem der Parameter mit 95% Sicherheit liegt.

* Umschlie√üt KI die 0 nicht (Koeffizient ungleich 0), kommt dies einem signifikanten Testergebnis gleich
]

---
class: top, left
### Multiple Regression

#### Omnibus-Test

Omnibustest des Gesamtmodells kann folgende Hypothese pr√ºfen:

* `\(H_0: \beta_1 = \beta_2 = 0\)`
* `\(H_1: \beta_j \neq 0\)`

`\(\rightarrow\)` Mithilfe des Omnibus-Tests kann √ºberpr√ºft werden, ob bei zumindest einer der UVs der lineare Zusammenhang mit der AV ungleich 0 ist (bei Konstanthaltung der jeweils anderen UV).

**Anders gesagt:**

* Pr√ºfung, ob Modell mit Pr√§diktoren signifikant mehr Varianz der AV erkl√§rt als ohne.
* Es werden Varianzen verwendet `\(\rightarrow\)` Teststatistik ist wieder der von der ANOVA bekannte F-Wert

---
class: top, left
### Multiple Regression

#### Omnibus-Test

Die Teststatistik des Omnibus-Tests ist wie folgt definiert:

`$$F = \frac{\frac{1}{2}\sum\limits _{i=1}^{n}(\hat{Y}_i - \bar{Y})^2}{\frac{1}{n-3}\sum\limits _{i=1}^{n}(Y_i - \hat{Y}_i)^2} = \frac{\frac{1}{2}\sum\limits _{i=1}^{n}(\hat{Y}_i - \bar{Y})^2}{s^2}$$`

* Unter der Geltung der Nullhypothese folgt diese Teststatistik einer F-Verteilung.

* Der kritische Bereich liegt auf der rechten Seite.

---
class: top, left
### Multiple Regression

#### Omnibus-Test

.pull-left[
.code60[

```r
model = lm(Aggression ~ TV + Emotionsregulation, data = df)
summary(model)
```

```
## 
## Call:
## lm(formula = Aggression ~ TV + Emotionsregulation, data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -18.4040  -6.2847   0.7681   7.6023  19.7061 
## 
## Coefficients:
##                    Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)        86.24294    6.70484  12.863 &lt; 0.0000000000000002 ***
## TV                  0.11254    0.68819   0.164                0.871    
## Emotionsregulation -0.52752    0.09961  -5.296           0.00000308 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 9.604 on 47 degrees of freedom
## Multiple R-squared:  0.3852,	Adjusted R-squared:  0.3591 
## F-statistic: 14.73 on 2 and 47 DF,  p-value: 0.00001083
```
]
]

.pull-right[
Dieser Wert findet sich im unteren Bereich des R Outputs:

`$$F = \frac{\frac{1}{2}\sum\limits _{i=1}^{n}(\hat{Y}_i - \bar{Y})^2}{s^2}= 14.73$$`

mit `\(df_{Z√§hler}=2\)` und `\(df_{Nenner}=47\)`

* `\(p=0.00001083&lt;.05\)`

* Das Gesamtmodell mit den Pr√§diktoren erkl√§rt signifikant mehr Varianz, als das Modell ohne Pr√§diktoren.
]

---
class: top, left
### Multiple Regression

#### Omnibus-Test - Modellvergleiche

* Der Omnibus-Test erm√∂glicht uns auch den Vergleich von 2 Modellen miteinander

* Voraussetzung ist, dass das eine Modell (komplex) das andere Modell (einfach) enh√§lt (geschachtelte Modelle; engl.: "*nested models*").

* Dies z.B. der Fall, wenn wir zu einem bestehenden Modell einen Pr√§diktor hinzunehmen

* Wir probieren dies in unserem Beispiel, indem wir zu unserem Modell den Pr√§diktor "Ausgrenzungserfahrung" hinzunehmen

  * **Szenario 1:** Ausgrenzungserfahrung ist kein relevanter Pr√§diktor - Modell ohne Ausgrenzungserfahrung erkl√§rt Daten zumindest gleich gut
  * **Szenario 2:** Modell mit Ausgrenzungserfahrung hat signifikant bessere Modellpassung (kann AV besser vorhersagen)

---
class: top, left
### Multiple Regression

#### Omnibus-Test - Modellvergleiche

.pull-left[
.code60[

```r
# Aufstellen einfaches Modell:

model1 = lm(Aggression ~ TV + Emotionsregulation, data = df)

# Aufstellen komplexes Modell:

model2 = lm(Aggression ~ TV + Emotionsregulation + Ausgrenzung, data = df)

# Das einfache Modell ist in das komplexe Modell "geschachtelt"
```
]
]

.pull-right[
.code60[

```r
# Omnibus-Test zum Vergleich "geschachtelter" Modelle

anova(model1, model2)
```

```
## Analysis of Variance Table
## 
## Model 1: Aggression ~ TV + Emotionsregulation
## Model 2: Aggression ~ TV + Emotionsregulation + Ausgrenzung
##   Res.Df    RSS Df Sum of Sq      F   Pr(&gt;F)   
## 1     47 4335.5                                
## 2     46 3508.3  1     827.2 10.846 0.001909 **
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```
]
]

Das komplexe Modell (inklusive Pr√§diktor Ausgrenzung) kann AV signifikant besser vorhersagen als das einfache Modell `\((p=0.001909&lt;.05)\)`

---
class: top, left
### Multiple Regression

#### Hinzunahme weiterer Pr√§diktoren

.pull-left[
.code60[

```r
# Aufstellen einfaches Modell:

model1 = lm(Aggression ~ TV + Emotionsregulation, data = df)
summary(model1)
```

```
## 
## Call:
## lm(formula = Aggression ~ TV + Emotionsregulation, data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -18.4040  -6.2847   0.7681   7.6023  19.7061 
## 
## Coefficients:
##                    Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)        86.24294    6.70484  12.863 &lt; 0.0000000000000002 ***
## TV                  0.11254    0.68819   0.164                0.871    
## Emotionsregulation -0.52752    0.09961  -5.296           0.00000308 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 9.604 on 47 degrees of freedom
## Multiple R-squared:  0.3852,	Adjusted R-squared:  0.3591 
## F-statistic: 14.73 on 2 and 47 DF,  p-value: 0.00001083
```
]
]

.pull-right[
.code60[

```r
# Aufstellen komplexes Modell:

model2 = lm(Aggression ~ TV + Emotionsregulation + Ausgrenzung, data = df)
summary(model2)
```

```
## 
## Call:
## lm(formula = Aggression ~ TV + Emotionsregulation + Ausgrenzung, 
##     data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.6668  -7.6041   0.2665   6.8444  18.4565 
## 
## Coefficients:
##                    Estimate Std. Error t value      Pr(&gt;|t|)    
## (Intercept)        65.59233    8.74569   7.500 0.00000000163 ***
## TV                  0.40650    0.63209   0.643       0.52335    
## Emotionsregulation -0.41784    0.09651  -4.330 0.00007997688 ***
## Ausgrenzung         0.27409    0.08322   3.293       0.00191 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 8.733 on 46 degrees of freedom
## Multiple R-squared:  0.5025,	Adjusted R-squared:  0.4701 
## F-statistic: 15.49 on 3 and 46 DF,  p-value: 0.0000004219
```
]
]

---
class: top, left
### Multiple Regression

#### Hinzunahme weiterer Pr√§diktoren

.pull-left[
Was passiert?

* Weiterer Pr√§diktor wird an Modell "drangeh√§ngt"

* Er erh√§lt ebenfalls einen Steigungsparameter, dieser erh√§lt einen Signifikanztest
  * Mit weiterem Punkt Ausgrenzungserfahrung nimmt Aggression um `\(\beta_3=0.27\)` Punkte zu
  * Ausgrenzungserfahrung kann Aggression signifikant vorhersagen `\((p=0.00191)\)`

* Y-Achsenabschnitt ist nun der Wert der AV, wenn alle 3 Pr√§diktoren = 0 sind.
]

.pull-right[
.code60[

```r
# Aufstellen komplexes Modell:

model2 = lm(Aggression ~ TV + Emotionsregulation + Ausgrenzung, data = df)
summary(model2)
```

```
## 
## Call:
## lm(formula = Aggression ~ TV + Emotionsregulation + Ausgrenzung, 
##     data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.6668  -7.6041   0.2665   6.8444  18.4565 
## 
## Coefficients:
##                    Estimate Std. Error t value      Pr(&gt;|t|)    
## (Intercept)        65.59233    8.74569   7.500 0.00000000163 ***
## TV                  0.40650    0.63209   0.643       0.52335    
## Emotionsregulation -0.41784    0.09651  -4.330 0.00007997688 ***
## Ausgrenzung         0.27409    0.08322   3.293       0.00191 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 8.733 on 46 degrees of freedom
## Multiple R-squared:  0.5025,	Adjusted R-squared:  0.4701 
## F-statistic: 15.49 on 3 and 46 DF,  p-value: 0.0000004219
```
]
]

---
class: top, left
### Multiple Regression

#### Modellpassung

* Auch f√ºr die multiple Regression l√§sst sich die G√ºte des Modells √ºber `\(R^2\)` sch√§tzen

* Zur Erinnerung: 
  * Verh√§ltnis aufgekl√§rter zu gesamter Streuung
  * `\(0‚â§ùëÖ^2‚â§1\)`
  * Je n√§her `\(R^2\)` an 1, desto besser passt sich Modell an Beobachtungspunkte an
  
* Die Hinzunahme weiterer Pr√§diktoren erh√∂ht i.d.R. die Modellpassung

---
class: top, left
### Multiple Regression

#### Modellpassung

.pull-left[
.code60[

```
## 
## Call:
## lm(formula = Aggression ~ TV + Emotionsregulation, data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -18.4040  -6.2847   0.7681   7.6023  19.7061 
## 
## Coefficients:
##                    Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)        86.24294    6.70484  12.863 &lt; 0.0000000000000002 ***
## TV                  0.11254    0.68819   0.164                0.871    
## Emotionsregulation -0.52752    0.09961  -5.296           0.00000308 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 9.604 on 47 degrees of freedom
## Multiple R-squared:  0.3852,	Adjusted R-squared:  0.3591 
## F-statistic: 14.73 on 2 and 47 DF,  p-value: 0.00001083
```
]
]

.pull-right[
.code60[

```
## 
## Call:
## lm(formula = Aggression ~ TV + Emotionsregulation + Ausgrenzung, 
##     data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.6668  -7.6041   0.2665   6.8444  18.4565 
## 
## Coefficients:
##                    Estimate Std. Error t value      Pr(&gt;|t|)    
## (Intercept)        65.59233    8.74569   7.500 0.00000000163 ***
## TV                  0.40650    0.63209   0.643       0.52335    
## Emotionsregulation -0.41784    0.09651  -4.330 0.00007997688 ***
## Ausgrenzung         0.27409    0.08322   3.293       0.00191 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 8.733 on 46 degrees of freedom
## Multiple R-squared:  0.5025,	Adjusted R-squared:  0.4701 
## F-statistic: 15.49 on 3 and 46 DF,  p-value: 0.0000004219
```
]
]

* Einfaches Modell (links): `\(R^2=.39 \rightarrow\)` Es k√∂nnen 39% der AV (Aggression) durch TV und Emotionsregulation erkl√§rt werden.
* Komplexes Modell (rechts): `\(R^2=.50 \rightarrow\)` Es k√∂nnen weitere 11% der AV durch Ausgrenzung erkl√§rt werden.

---
class: top, left
### Multiple Regression

.pull-left[
#### Vorhersagewerte - Anwendung des Modells

`$$Y_i= 86.24 + 0.11 \cdot X_{i1} + -0.53 \cdot X_{i2} + \epsilon_i$$`

* Mit der aufgestellten Modellgleichung, k√∂nnen wir Werte vorhersagen.

**Beispiel** f√ºr Person `\(i=1\)`:

`$$\hat{Y}_i= 86.24294 + 0.11254 \cdot 5 + -0.52752 \cdot 50 = 60.43$$`

* Laut unserem Modell mit 2 Pr√§diktoren, sollte Person 1 einen Aggressionswert von 60.29 Punkten haben.

* Da der tats√§chlich beobachtete Wert 53 ist, betr√§gt der Modellfehler `\(60.29-53=7.29\)` Punkte.

]


.pull-right[

&lt;table class=" lightable-classic" style='font-size: 16px; font-family: "Arial Narrow", "Source Sans Pro", sans-serif; width: auto !important; margin-left: auto; margin-right: auto;'&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; Aggression &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; TV &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Emotionsregulation &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Ausgrenzung &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 53 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 55 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 57 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 58 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 58 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 80 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 71 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 61 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 49 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 62 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 41 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 49 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 82 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 36 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 63 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 66 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 40 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 62 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 44 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 47 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 30 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 51 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 56 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 56 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 54 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 68 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 38 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 76 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 78 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 65 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 56 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 38 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 65 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 31 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 61 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 52 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 98 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 53 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 64 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 37 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]

---
class: top, left
### Multiple Regression

.pull-left[
#### Vorhersagewerte - Anwendung des Modells

Wir k√∂nnen mit R automatisch die Wert f√ºr unsere Modelle sch√§tzen:

F√ºr das Modell mit TV und Emotionsregulation:

.code80[

```r
df$pred_model1 = round(predict(model1, newdata = df), 2)
```

F√ºr das Modell mit TV, Emotionsregulation und Ausgrenzung:

```r
df$pred_model2 = round(predict(model2, newdata = df), 2)
```
]
]

.pull-right[

&lt;table class=" lightable-classic" style='font-size: 16px; font-family: "Arial Narrow", "Source Sans Pro", sans-serif; width: auto !important; margin-left: auto; margin-right: auto;'&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; Aggression &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; TV &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Emotionsregulation &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Ausgrenzung &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; pred_model1 &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; pred_model2 &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 53 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 55 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 60.43 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 61.81 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 57 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 58 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 58 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 56.21 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 59.29 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 80 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 71 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 68.34 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 72.46 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 61 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 49 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 61.29 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 57.96 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 62 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 41 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 49 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 65.06 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 63.52 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 82 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 36 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 63 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 68.26 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 71.48 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 66 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 40 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 62 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 65.25 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 66.28 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 44 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 47 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 30 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 62.01 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 56.21 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 51 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 56 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 56 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 57.26 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 59.57 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 54 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 68 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 38 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50.93 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 49.63 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 76 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 78 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 68.45 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 74.79 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 65 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 56 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 38 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 57.15 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 54.23 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 65 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 31 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 70.34 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 63.86 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 61 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 52 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 98 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 59.04 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 71.54 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 53 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 64 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 37 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 52.71 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 49.80 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]

---
class: top, left
### Multiple Regression

.pull-left[
#### Vorhersagewerte - Anwendung des Modells

* Je besser das Modell passt, desto st√§rker der Zusammenhang zwischen beobachteten und vorhergesagten Werten:
]

.pull-right[

![](Statistik_II_6_WS24_files/figure-html/unnamed-chunk-29-1.png)&lt;!-- --&gt;
]

---
class: top, left
### Multiple Regression

#### Voraussetzungen der multiplen Regression

**Wie bei einfacher Regression:**

1) Das Kriterium (AV) muss intervallskaliert und normalverteilt sein.

2) Die Pr√§diktoren (UV) k√∂nnen entweder intervallskaliert und normalverteilt oder dichotom nominalskaliert sein.

3) Die Werte der einzelnen Versuchspersonen m√ºssen unabh√§ngig voneinander sein

4) Die Zusammenh√§nge m√ºssen theroretisch linear sein (sonst andere Regressionsmodelle nutzen).

5) Streuungen der Wertepaare m√ºssen √ºber ganzen Wertebereich von `\(X\)` und `\(Z\)` homogen sein (Homoskedastizit√§t).

**Nur bei multipler Regression:**

6) Multikollinearit√§t: Pr√§diktoren sollten nicht zu stark miteinander korrelieren

---
class: top, left
### Multiple Regression

#### Voraussetzungen der multiplen Regression

**Normalverteilung der Residuen:**

.code60[
.pull-left[
.center[

```r
qqnorm(rstandard(model1), cex = 1.5)
qqline(rstandard(model1))
```

&lt;img src="Statistik_II_6_WS24_files/figure-html/unnamed-chunk-30-1.png" height="300px" /&gt;
]
]

.pull-right[

```r
model1 = lm(Aggression ~ TV + Emotionsregulation, data = df)
shapiro.test(rstandard(model1))
```

```
## 
## 	Shapiro-Wilk normality test
## 
## data:  rstandard(model1)
## W = 0.98337, p-value = 0.6997
```

Benchmarks:

* QQ-Plot: Punkte sollten m√∂glichst auf der 45 Grad Diagonalen liegen
* Shapiro-Wilk Test: p-Wert sollte &gt; als `\(\alpha=.05\)` sein

]
]


---
class: top, left
### Multiple Regression

#### Voraussetzungen der multiplen Regression

**Homoskedastizit√§t:**

.pull-left[
.center[

```r
model1 = lm(Aggression ~ TV + Emotionsregulation, data = df)
plot(model1, 1, cex = 2)
```

&lt;img src="Statistik_II_6_WS24_files/figure-html/unnamed-chunk-32-1.png" height="300px" /&gt;
]
]

.pull-right[
* Plot der standardisierten Residuen gegen die standardisierten vorhergesagten Werte

* Ideal ist eine Punktewolke ohne Systematik (Pattern)

* Die Linie sollte relativ horizontal verlaufen

`\(\rightarrow\)` dann ist Homoskedastizit√§tsannahme gegeben
]

---
class: top, left
### Multiple Regression

#### Voraussetzungen der multiplen Regression

**Multikollinearit√§t:**

Drei Methoden zur Pr√ºfung von Multikollinearit√§t:

* Korrelationsmatrix f√ºr hohe Korrelationen scannen

* Variance inflation factor (VIF) 

* Toleranz-Statistik (1/VIF)

Benchmarks f√ºr potentielle Multikolliniarit√§tsproblematik:

* Korrelationen mit `\(r&gt;.9\)` k√∂nnen Probleme bereiten
* gr√∂√üter VIF gr√∂√üer als 10 (Bowerman &amp; O‚ÄòConnel, 1990)
* Durchschnittlicher VIF substanziell gr√∂√üer als 1 
* Toleranz niedriger als 0.1 (ernstes Problem)
* Toleranz niedriger als 0.2 (potentielles Problem)


---
class: top, left
### Multiple Regression

#### Voraussetzungen der multiplen Regression

**Multikollinearit√§t:**

Korrelationsmatrix f√ºr hohe Korrelationen scannen:

```r
cor(df[, c("Aggression", "TV", "Emotionsregulation")])
```

```
##                    Aggression         TV Emotionsregulation
## Aggression          1.0000000  0.1357292         -0.6203926
## TV                  0.1357292  1.0000000         -0.1891767
## Emotionsregulation -0.6203926 -0.1891767          1.0000000
```

`\(\rightarrow\)` Keine der bivariaten Korrelationen zwischen den Pr√§diktoren ist `\(r&gt;.9\)`


---
class: top, left
### Multiple Regression

#### Voraussetzungen der multiplen Regression

**Multikollinearit√§t:**

VIF und Toleranz berechnen:


```r
library(olsrr)

ols_vif_tol(model1)
```

```
##            Variables Tolerance      VIF
## 1                 TV 0.9642122 1.037116
## 2 Emotionsregulation 0.9642122 1.037116
```

* Kein VIF gr√∂√üer als 10
* Durchschnittlicher VIF nicht substanziell gr√∂√üer als 1 
* Toleranz nicht niedriger als 0.2

`\(\rightarrow\)` Es scheint kein Multikollinearit√§tsproblem vorzuliegen.

---
class: top, left
### Take-aways

.full-width[.content-box-gray[
* Die Multiple Regression erm√∂glicht die Erweiterung des Regressionsmodells um **weitere Pr√§diktoren**.

* Im Gegensatz zur mehrfaktoriellen ANOVA, d√ºrfen **auch stetige UVs** verwendet werden.

* Damit kann die **Modellpassung** und somit die **Vorhersageg√ºte** erh√∂ht werden.

* Darstellung bei 2 Pr√§diktoren entspricht einer **Ebene** im 3D Raum.

* Es k√∂nnen **Hypothesentests** f√ºr die einzelnen Koeffizienten (Pr√§diktoren) und f√ºr das Gesamtmodell (Omnibustest) gepr√ºft werden.

* Je mehr systematisch pr√§diktive UVs das Modell enth√§lt, desto eher werden **vorhergesagte Werte** den tats√§chlich beobachteten entsprechen.

* Als zus√§tzliche Modellvoraussetzung muss die **Multikollinearit√§t** gepr√ºft werden
]
]


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
